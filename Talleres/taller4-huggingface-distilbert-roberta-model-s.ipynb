{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Integrantes:\n\n### * Mariana Ceballos\n### * Felipe Londoño\n### * Federico Arango\n### * Daniel Elorza","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-26T02:23:09.145047Z","iopub.execute_input":"2023-10-26T02:23:09.145478Z","iopub.status.idle":"2023-10-26T02:23:09.156008Z","shell.execute_reply.started":"2023-10-26T02:23:09.145441Z","shell.execute_reply":"2023-10-26T02:23:09.154726Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:23:12.511815Z","iopub.execute_input":"2023-10-26T02:23:12.512178Z","iopub.status.idle":"2023-10-26T02:23:12.695632Z","shell.execute_reply.started":"2023-10-26T02:23:12.512150Z","shell.execute_reply":"2023-10-26T02:23:12.694672Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:23:29.863598Z","iopub.execute_input":"2023-10-26T02:23:29.864006Z","iopub.status.idle":"2023-10-26T02:23:29.889645Z","shell.execute_reply.started":"2023-10-26T02:23:29.863973Z","shell.execute_reply":"2023-10-26T02:23:29.888352Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9844223a6711493bb2b8696f5faaccb2"}},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:23:55.148390Z","iopub.execute_input":"2023-10-26T02:23:55.149390Z","iopub.status.idle":"2023-10-26T02:23:56.550255Z","shell.execute_reply.started":"2023-10-26T02:23:55.149324Z","shell.execute_reply":"2023-10-26T02:23:56.549132Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Category'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:23:59.389523Z","iopub.execute_input":"2023-10-26T02:23:59.389956Z","iopub.status.idle":"2023-10-26T02:23:59.443738Z","shell.execute_reply.started":"2023-10-26T02:23:59.389902Z","shell.execute_reply":"2023-10-26T02:23:59.442565Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  Category\n0  One of the other reviewers has mentioned that ...  positive         1\n1  A wonderful little production. <br /><br />The...  positive         1\n2  I thought this was a wonderful way to spend ti...  positive         1\n3  Basically there's a family where a little boy ...  negative         0\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:01.780461Z","iopub.execute_input":"2023-10-26T02:24:01.780847Z","iopub.status.idle":"2023-10-26T02:24:01.788241Z","shell.execute_reply.started":"2023-10-26T02:24:01.780814Z","shell.execute_reply":"2023-10-26T02:24:01.787012Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(50000, 3)"},"metadata":{}}]},{"cell_type":"code","source":"df = df.rename(columns={\n    'review': 'text',\n    'Category': 'label'\n})\n","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:03.558010Z","iopub.execute_input":"2023-10-26T02:24:03.558410Z","iopub.status.idle":"2023-10-26T02:24:03.566215Z","shell.execute_reply.started":"2023-10-26T02:24:03.558347Z","shell.execute_reply":"2023-10-26T02:24:03.565059Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:05.228855Z","iopub.execute_input":"2023-10-26T02:24:05.229743Z","iopub.status.idle":"2023-10-26T02:24:05.245640Z","shell.execute_reply.started":"2023-10-26T02:24:05.229693Z","shell.execute_reply":"2023-10-26T02:24:05.244418Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"1    25000\n0    25000\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:07.584446Z","iopub.execute_input":"2023-10-26T02:24:07.585199Z","iopub.status.idle":"2023-10-26T02:24:08.219676Z","shell.execute_reply.started":"2023-10-26T02:24:07.585166Z","shell.execute_reply":"2023-10-26T02:24:08.218410Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test = train_test_split(df, test_size = 0.2)\nX_train, X_val = train_test_split(X_train, test_size = 0.2) ","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:09.052352Z","iopub.execute_input":"2023-10-26T02:24:09.053328Z","iopub.status.idle":"2023-10-26T02:24:09.076409Z","shell.execute_reply.started":"2023-10-26T02:24:09.053293Z","shell.execute_reply":"2023-10-26T02:24:09.075577Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(X_train.head())","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:11.535716Z","iopub.execute_input":"2023-10-26T02:24:11.536104Z","iopub.status.idle":"2023-10-26T02:24:11.544059Z","shell.execute_reply.started":"2023-10-26T02:24:11.536064Z","shell.execute_reply":"2023-10-26T02:24:11.542898Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"                                                    text sentiment  label\n49998  I'm going to have to disagree with the previou...  negative      0\n44684  I really enjoyed this movie about the relation...  positive      1\n5212   Be warned by the line on the back of the box t...  negative      0\n38270  Just watched this after my mother brought it b...  positive      1\n36665  Picture the scene: a mountainous alien landsca...  positive      1\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:17.366052Z","iopub.execute_input":"2023-10-26T02:24:17.366498Z","iopub.status.idle":"2023-10-26T02:24:18.077697Z","shell.execute_reply.started":"2023-10-26T02:24:17.366461Z","shell.execute_reply":"2023-10-26T02:24:18.076752Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(X_train, split=\"train\")\ntest_ds = Dataset.from_pandas(X_val, split = 'test')\nval_ds = Dataset.from_pandas(X_test, split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:20.120443Z","iopub.execute_input":"2023-10-26T02:24:20.121112Z","iopub.status.idle":"2023-10-26T02:24:20.288943Z","shell.execute_reply.started":"2023-10-26T02:24:20.121077Z","shell.execute_reply":"2023-10-26T02:24:20.288030Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:22.686147Z","iopub.execute_input":"2023-10-26T02:24:22.686556Z","iopub.status.idle":"2023-10-26T02:24:22.693714Z","shell.execute_reply.started":"2023-10-26T02:24:22.686524Z","shell.execute_reply":"2023-10-26T02:24:22.692513Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'sentiment', 'label', '__index_level_0__'],\n    num_rows: 32000\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:25.490179Z","iopub.execute_input":"2023-10-26T02:24:25.490600Z","iopub.status.idle":"2023-10-26T02:24:27.235785Z","shell.execute_reply.started":"2023-10-26T02:24:25.490568Z","shell.execute_reply":"2023-10-26T02:24:27.234821Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:29.825400Z","iopub.execute_input":"2023-10-26T02:24:29.826067Z","iopub.status.idle":"2023-10-26T02:24:30.542064Z","shell.execute_reply.started":"2023-10-26T02:24:29.826034Z","shell.execute_reply":"2023-10-26T02:24:30.541120Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0edb96f3f54315bfd49738b94948c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72eda098f284553b4a74321c9104aeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"833b28944df04b6a96b95cf23a2d7d5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8149003cc4ce41b5898ac421bd96e113"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:35.546600Z","iopub.execute_input":"2023-10-26T02:24:35.547432Z","iopub.status.idle":"2023-10-26T02:24:35.552597Z","shell.execute_reply.started":"2023-10-26T02:24:35.547395Z","shell.execute_reply":"2023-10-26T02:24:35.551425Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenized_train = train_ds.map(preprocess_function, batched=True)\ntokenized_val = val_ds.map(preprocess_function, batched=True)\ntokenized_test = test_ds.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:24:53.064325Z","iopub.execute_input":"2023-10-26T02:24:53.064792Z","iopub.status.idle":"2023-10-26T02:25:20.723428Z","shell.execute_reply.started":"2023-10-26T02:24:53.064757Z","shell.execute_reply":"2023-10-26T02:25:20.722084Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182c3c19b36744b59ecde8d6f1d38ebc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36681da29e8e4df390a91e21693c6bc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"309a27ed594e40218884b947257c10a0"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:25:25.005649Z","iopub.execute_input":"2023-10-26T02:25:25.006030Z","iopub.status.idle":"2023-10-26T02:25:35.759226Z","shell.execute_reply.started":"2023-10-26T02:25:25.005999Z","shell.execute_reply":"2023-10-26T02:25:35.758159Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:25:37.296956Z","iopub.execute_input":"2023-10-26T02:25:37.298673Z","iopub.status.idle":"2023-10-26T02:25:37.303208Z","shell.execute_reply.started":"2023-10-26T02:25:37.298626Z","shell.execute_reply":"2023-10-26T02:25:37.302244Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:25:39.424002Z","iopub.execute_input":"2023-10-26T02:25:39.424408Z","iopub.status.idle":"2023-10-26T02:25:54.096508Z","shell.execute_reply.started":"2023-10-26T02:25:39.424354Z","shell.execute_reply":"2023-10-26T02:25:54.095133Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:04.072296Z","iopub.execute_input":"2023-10-26T02:26:04.072766Z","iopub.status.idle":"2023-10-26T02:26:06.766942Z","shell.execute_reply.started":"2023-10-26T02:26:04.072727Z","shell.execute_reply":"2023-10-26T02:26:06.765763Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:09.221885Z","iopub.execute_input":"2023-10-26T02:26:09.222278Z","iopub.status.idle":"2023-10-26T02:26:09.685155Z","shell.execute_reply.started":"2023-10-26T02:26:09.222245Z","shell.execute_reply":"2023-10-26T02:26:09.684241Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af81298dd3d240da85487972fb0166b8"}},"metadata":{}}]},{"cell_type":"code","source":"id2label = {0: \"negative\", 1: \"positive\"}\nlabel2id = {\"negative\": 0, \"positive\": 1}","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:18.279497Z","iopub.execute_input":"2023-10-26T02:26:18.280404Z","iopub.status.idle":"2023-10-26T02:26:18.285755Z","shell.execute_reply.started":"2023-10-26T02:26:18.280335Z","shell.execute_reply":"2023-10-26T02:26:18.284429Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:19.989137Z","iopub.execute_input":"2023-10-26T02:26:19.989903Z","iopub.status.idle":"2023-10-26T02:26:20.042714Z","shell.execute_reply.started":"2023-10-26T02:26:19.989861Z","shell.execute_reply":"2023-10-26T02:26:20.041812Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:31.245192Z","iopub.execute_input":"2023-10-26T02:26:31.246108Z","iopub.status.idle":"2023-10-26T02:26:33.885137Z","shell.execute_reply.started":"2023-10-26T02:26:31.246071Z","shell.execute_reply":"2023-10-26T02:26:33.883870Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8cf9b3ef1ac477994598a6baf35c8b2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"imdbreviews_classification_distilbert_v02\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:43.203530Z","iopub.execute_input":"2023-10-26T02:26:43.204541Z","iopub.status.idle":"2023-10-26T02:26:43.302820Z","shell.execute_reply.started":"2023-10-26T02:26:43.204498Z","shell.execute_reply":"2023-10-26T02:26:43.301564Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:26:55.946296Z","iopub.execute_input":"2023-10-26T02:26:55.946738Z","iopub.status.idle":"2023-10-26T02:28:25.374141Z","shell.execute_reply.started":"2023-10-26T02:26:55.946702Z","shell.execute_reply":"2023-10-26T02:28:25.373076Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Cloning https://huggingface.co/dfelorza/imdbreviews_classification_distilbert_v02 into local empty directory.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Download file pytorch_model.bin:   0%|          | 8.00k/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"934f59ded7364cbd9a0c52082b4dca32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/Sep04_13-44-32_ab34179d5153/events.out.tfevents.1693835161.ab34179d5153.99.0: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edc6ab3117f14ead884502ffd164980f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file training_args.bin: 100%|##########| 3.93k/3.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e242c6ab337445ff92b5957e088c1ac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/Sep04_13-44-32_ab34179d5153/events.out.tfevents.1693835161.ab34179d5153.99.0:  19%|#9        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74901767b99f450cb3ce25cbe15f361d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file training_args.bin:  25%|##5       | 1.00k/3.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"612cc5be2cf14b4aa310b6ad27e1c2d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/Sep02_15-41-33_61d2b8212c93/events.out.tfevents.1693669310.61d2b8212c93.28.0: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a751d10bb9249b7872dda2c2d2da1fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/Sep02_15-41-33_61d2b8212c93/events.out.tfevents.1693669310.61d2b8212c93.28.0:  19%|#9        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2da2f8ea5324ede97aaa2705700b545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file pytorch_model.bin:   0%|          | 1.00k/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"927d897bd96c4d81819844bb65f397de"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T02:28:33.193172Z","iopub.execute_input":"2023-10-26T02:28:33.194046Z","iopub.status.idle":"2023-10-26T03:03:05.656441Z","shell.execute_reply.started":"2023-10-26T02:28:33.193995Z","shell.execute_reply":"2023-10-26T03:03:05.655037Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231026_023102-mrpynpfm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/danielelorza/huggingface/runs/mrpynpfm' target=\"_blank\">scarlet-thunder-3</a></strong> to <a href='https://wandb.ai/danielelorza/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/danielelorza/huggingface' target=\"_blank\">https://wandb.ai/danielelorza/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/danielelorza/huggingface/runs/mrpynpfm' target=\"_blank\">https://wandb.ai/danielelorza/huggingface/runs/mrpynpfm</a>"},"metadata":{}},{"name":"stderr","text":"You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 31:25, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.207200</td>\n      <td>0.213929</td>\n      <td>0.922600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.138500</td>\n      <td>0.191969</td>\n      <td>0.932600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2000, training_loss=0.19300100326538086, metrics={'train_runtime': 2072.032, 'train_samples_per_second': 30.888, 'train_steps_per_second': 0.965, 'total_flos': 8472904590472320.0, 'train_loss': 0.19300100326538086, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:04:18.138513Z","iopub.execute_input":"2023-10-26T03:04:18.139893Z","iopub.status.idle":"2023-10-26T03:04:18.983208Z","shell.execute_reply.started":"2023-10-26T03:04:18.139853Z","shell.execute_reply":"2023-10-26T03:04:18.981930Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Freeze all layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the classifier layer\nfor param in model.classifier.parameters():\n    param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:04:22.188710Z","iopub.execute_input":"2023-10-26T03:04:22.189095Z","iopub.status.idle":"2023-10-26T03:04:22.198352Z","shell.execute_reply.started":"2023-10-26T03:04:22.189065Z","shell.execute_reply":"2023-10-26T03:04:22.196865Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:04:24.409174Z","iopub.execute_input":"2023-10-26T03:04:24.410257Z","iopub.status.idle":"2023-10-26T03:04:24.421428Z","shell.execute_reply.started":"2023-10-26T03:04:24.410212Z","shell.execute_reply":"2023-10-26T03:04:24.420026Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"imdbreviews_classification_distilbert_v02_clf_finetuning\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:04:39.773515Z","iopub.execute_input":"2023-10-26T03:04:39.774526Z","iopub.status.idle":"2023-10-26T03:04:39.785070Z","shell.execute_reply.started":"2023-10-26T03:04:39.774484Z","shell.execute_reply":"2023-10-26T03:04:39.783662Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:04:49.194793Z","iopub.execute_input":"2023-10-26T03:04:49.195664Z","iopub.status.idle":"2023-10-26T03:06:08.884001Z","shell.execute_reply.started":"2023-10-26T03:04:49.195606Z","shell.execute_reply":"2023-10-26T03:06:08.882755Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Cloning https://huggingface.co/dfelorza/imdbreviews_classification_distilbert_v02_clf_finetuning into local empty directory.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Download file pytorch_model.bin:   0%|          | 8.00k/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1e8940250e43f1bbdd056587a03e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/Sep04_14-18-44_ab34179d5153/events.out.tfevents.1693837137.ab34179d5153.99.1: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84cbdca528b449c6aac3d4f4c33eb5b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file training_args.bin: 100%|##########| 3.93k/3.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5c558cd5b6d4b718e64218bc86f5ffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/Sep04_14-18-44_ab34179d5153/events.out.tfevents.1693837137.ab34179d5153.99.1:  19%|#8        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"916432a303584413abfe3f8fe1dca9aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file training_args.bin:  25%|##5       | 1.00k/3.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e5ac46daa1f417582392611eb1760d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file pytorch_model.bin:   0%|          | 1.00k/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b592c0549ef542968e58f4276717cbcc"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:06:45.135538Z","iopub.execute_input":"2023-10-26T03:06:45.136285Z","iopub.status.idle":"2023-10-26T03:22:45.381788Z","shell.execute_reply.started":"2023-10-26T03:06:45.136249Z","shell.execute_reply":"2023-10-26T03:22:45.377467Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 15:59, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.688600</td>\n      <td>0.685385</td>\n      <td>0.660600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.685100</td>\n      <td>0.682345</td>\n      <td>0.701700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2000, training_loss=0.6879482421875, metrics={'train_runtime': 959.6149, 'train_samples_per_second': 66.693, 'train_steps_per_second': 2.084, 'total_flos': 8472904590472320.0, 'train_loss': 0.6879482421875, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Aplicación del Modelo de HuggingFace: \"roberta-base\"**","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:22:55.049176Z","iopub.execute_input":"2023-10-26T03:22:55.050410Z","iopub.status.idle":"2023-10-26T03:22:55.943329Z","shell.execute_reply.started":"2023-10-26T03:22:55.050339Z","shell.execute_reply":"2023-10-26T03:22:55.942156Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17efcdfdb1604b298f76c8451e0f5a46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8e5ebd0b2e4ebc86920448c36d7314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95813483fcdd414aa80a89374aa4b2f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4f3e6688e0443f9c53afb7c8f514ad"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:23:00.021399Z","iopub.execute_input":"2023-10-26T03:23:00.021978Z","iopub.status.idle":"2023-10-26T03:23:00.028595Z","shell.execute_reply.started":"2023-10-26T03:23:00.021941Z","shell.execute_reply":"2023-10-26T03:23:00.027388Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"tokenized_train = train_ds.map(preprocess_function, batched=True)\ntokenized_val = val_ds.map(preprocess_function, batched=True)\ntokenized_test = test_ds.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:23:02.486396Z","iopub.execute_input":"2023-10-26T03:23:02.486846Z","iopub.status.idle":"2023-10-26T03:23:29.892743Z","shell.execute_reply.started":"2023-10-26T03:23:02.486813Z","shell.execute_reply":"2023-10-26T03:23:29.890870Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9064804c0241406989acb60ba4b06eef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c49eadf930bc4195beef550d64362d65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29122f413005436a971badacacdd6b3b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:23:50.297649Z","iopub.execute_input":"2023-10-26T03:23:50.298051Z","iopub.status.idle":"2023-10-26T03:23:50.306018Z","shell.execute_reply.started":"2023-10-26T03:23:50.298018Z","shell.execute_reply":"2023-10-26T03:23:50.304858Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:23:53.051153Z","iopub.execute_input":"2023-10-26T03:23:53.051581Z","iopub.status.idle":"2023-10-26T03:23:53.059082Z","shell.execute_reply.started":"2023-10-26T03:23:53.051545Z","shell.execute_reply":"2023-10-26T03:23:53.057762Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:23:55.167518Z","iopub.execute_input":"2023-10-26T03:23:55.168456Z","iopub.status.idle":"2023-10-26T03:23:55.545214Z","shell.execute_reply.started":"2023-10-26T03:23:55.168418Z","shell.execute_reply":"2023-10-26T03:23:55.543814Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"roberta-base\", num_labels=2, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:23:57.978291Z","iopub.execute_input":"2023-10-26T03:23:57.979310Z","iopub.status.idle":"2023-10-26T03:24:01.443672Z","shell.execute_reply.started":"2023-10-26T03:23:57.979272Z","shell.execute_reply":"2023-10-26T03:24:01.442400Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da6fd86a3cb420eac1dc2481839ca42"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"imdbreviews_classification_roberta_v01\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:24:05.006597Z","iopub.execute_input":"2023-10-26T03:24:05.007381Z","iopub.status.idle":"2023-10-26T03:24:05.023573Z","shell.execute_reply.started":"2023-10-26T03:24:05.007322Z","shell.execute_reply":"2023-10-26T03:24:05.022293Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:24:09.065981Z","iopub.execute_input":"2023-10-26T03:24:09.066409Z","iopub.status.idle":"2023-10-26T03:24:13.614735Z","shell.execute_reply.started":"2023-10-26T03:24:09.066362Z","shell.execute_reply":"2023-10-26T03:24:13.613461Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Cloning https://huggingface.co/dfelorza/imdbreviews_classification_roberta_v01 into local empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T03:25:20.668295Z","iopub.execute_input":"2023-10-26T03:25:20.669467Z","iopub.status.idle":"2023-10-26T04:26:29.019740Z","shell.execute_reply.started":"2023-10-26T03:25:20.669425Z","shell.execute_reply":"2023-10-26T04:26:29.018428Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 1:01:06, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.155700</td>\n      <td>0.139779</td>\n      <td>0.951100</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.104900</td>\n      <td>0.160709</td>\n      <td>0.955500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2000, training_loss=0.15034868621826172, metrics={'train_runtime': 3667.917, 'train_samples_per_second': 17.449, 'train_steps_per_second': 0.545, 'total_flos': 1.682412665732544e+16, 'train_loss': 0.15034868621826172, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"roberta-base\", num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T04:26:29.022316Z","iopub.execute_input":"2023-10-26T04:26:29.023058Z","iopub.status.idle":"2023-10-26T04:26:30.512643Z","shell.execute_reply.started":"2023-10-26T04:26:29.023013Z","shell.execute_reply":"2023-10-26T04:26:30.511347Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Freeze all layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the classifier layer\nfor param in model.classifier.parameters():\n    param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2023-10-26T04:26:30.555222Z","iopub.execute_input":"2023-10-26T04:26:30.556092Z","iopub.status.idle":"2023-10-26T04:26:30.564474Z","shell.execute_reply.started":"2023-10-26T04:26:30.556053Z","shell.execute_reply":"2023-10-26T04:26:30.563329Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-10-26T04:26:30.572703Z","iopub.execute_input":"2023-10-26T04:26:30.573092Z","iopub.status.idle":"2023-10-26T04:26:30.588101Z","shell.execute_reply.started":"2023-10-26T04:26:30.573053Z","shell.execute_reply":"2023-10-26T04:26:30.586815Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"imdbreviews_classification_roberta_v01_clf_finetuning\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T04:26:30.589835Z","iopub.execute_input":"2023-10-26T04:26:30.590201Z","iopub.status.idle":"2023-10-26T04:26:30.602434Z","shell.execute_reply.started":"2023-10-26T04:26:30.590166Z","shell.execute_reply":"2023-10-26T04:26:30.600893Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T04:26:30.604058Z","iopub.execute_input":"2023-10-26T04:26:30.605652Z","iopub.status.idle":"2023-10-26T04:26:35.248797Z","shell.execute_reply.started":"2023-10-26T04:26:30.605612Z","shell.execute_reply":"2023-10-26T04:26:35.247304Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"Cloning https://huggingface.co/dfelorza/imdbreviews_classification_roberta_v01_clf_finetuning into local empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T04:26:35.251081Z","iopub.execute_input":"2023-10-26T04:26:35.251563Z","iopub.status.idle":"2023-10-26T04:55:53.677108Z","shell.execute_reply.started":"2023-10-26T04:26:35.251516Z","shell.execute_reply":"2023-10-26T04:55:53.673060Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 29:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.659600</td>\n      <td>0.649339</td>\n      <td>0.838700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.634900</td>\n      <td>0.632121</td>\n      <td>0.837400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2000, training_loss=0.655035415649414, metrics={'train_runtime': 1757.5757, 'train_samples_per_second': 36.414, 'train_steps_per_second': 1.138, 'total_flos': 1.682412665732544e+16, 'train_loss': 0.655035415649414, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}